{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vivek.VIVEKAGARWAL\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vivek.VIVEKAGARWAL\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet tokenization\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the file and converting to a dataframe\n",
    "MS_final = pd.read_csv('MS_tweets_2.csv')\n",
    "MS_final.head()\n",
    "\n",
    "MS_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet_ID', 'URL', 'User', 'Share', 'Tweet_text', 'Date', 'Retweets',\n",
       "       'Favorites', 'Mentions', 'Hashtags', 'GeoSpatial'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MS_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = MS_final['Tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Making PAVING Material out of it is a REALLY G...\n",
       "1    Yep! I don’t remember plastic as a child. It w...\n",
       "2    Lol....okay. Why dont you look up the U.S. deb...\n",
       "3    Learn how #MorganStanley helps clients protect...\n",
       "4    Perfect Friday field trip to @MorganStanley in...\n",
       "Name: Tweet_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping duplicates\n",
    "#for now\n",
    "#can analyze separately the value of duplicated tweets\n",
    "MS_final = MS_final.drop_duplicates(subset = 'Tweet_text', keep = 'first')\n",
    "MS_final.shape\n",
    "\n",
    "#just extracting the tweet text\n",
    "#tweets = MS_final['Tweet_text']\n",
    "MS_final.head()['Tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call .str on a Series object that contains string objects, you get to call string methods on all Series elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    making paving material out of it is a really g...\n",
       "1    yep! i don’t remember plastic as a child. it w...\n",
       "2    lol....okay. why dont you look up the u.s. deb...\n",
       "3    learn how #morganstanley helps clients protect...\n",
       "4    perfect friday field trip to @morganstanley in...\n",
       "Name: Tweet_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "MS_final['Tweet_text'] = MS_final['Tweet_text'].str.lower()\n",
    "MS_final.head()['Tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        making paving material out of it is a really g...\n",
       "1        yep! i don’t remember plastic as a child. it w...\n",
       "2        lol....okay. why dont you look up the u.s. deb...\n",
       "3        learn how #morganstanley helps clients protect...\n",
       "4        perfect friday field trip to @morganstanley in...\n",
       "5                                                      NaN\n",
       "6        did you know that consolidating your assets co...\n",
       "7        americans had better quit arguing about who ge...\n",
       "8        up 200 down 200 up 300 down 300 i feel like a ...\n",
       "9                                  glass...100% recyclable\n",
       "10       “walk the ridge” and see that there are good p...\n",
       "11       extremely proud to work with advocates like ci...\n",
       "13       welcome new partners! we are thrilled over a d...\n",
       "14       earlier this week we spent an amazing afternoo...\n",
       "15       hey @morganstanley why is it taking months to ...\n",
       "16       la divisione usa di deutsche bank non supera g...\n",
       "17       it will be so much worse - your orange benefac...\n",
       "18       yes, this happens at big firms too @morganstan...\n",
       "19       gli scheletri negli armadi vengono fuori. #deu...\n",
       "22       @morganstanley sf volunteered with communitygr...\n",
       "23       the hospital looked great..... glad we could h...\n",
       "24                                          #justiceforluz\n",
       "29       financials give up most or all of morning gain...\n",
       "30       the tenor of trade disputes is changing. they ...\n",
       "31       china becoming more affluent and influential i...\n",
       "32       en #alsonarlacampana con @victorpiz; @morganst...\n",
       "33       sat., june 30th is the deadline to sign up for...\n",
       "34       this week, the @bankingjournal podcast hosted ...\n",
       "35       huge thank you to the team of amazing voluntee...\n",
       "36       in china's lower-tier cities, the forecast is ...\n",
       "                               ...                        \n",
       "24970                  @morganstanley @potus how can help?\n",
       "24971    uncertainty health concerns unsecure trading.....\n",
       "24972    all investors face a crisis when trusting morg...\n",
       "24973    will asset taking continue to boom in 2020 by ...\n",
       "24974    if you killed him, then it was my order. also,...\n",
       "24975    @morganstanley @potus the media is ruthless to...\n",
       "24976    \"larger, well capitalized european corporates ...\n",
       "24977    how about the corruption if wallstreet and @mo...\n",
       "24978    @icegov you're being used as a political tool ...\n",
       "24979    alarmism is a word that’s absent from science ...\n",
       "24980    no, i will just continue to point out inconsis...\n",
       "24981    i encourage you to write something about it an...\n",
       "24982    so the pristine temp stations that do not need...\n",
       "24983    @potus @morganstanley i got this alert at 3:08...\n",
       "24984    halftime stats provided by @morganstanley #hoy...\n",
       "24985    the uscrn shows no increase in surface tempera...\n",
       "24986    thanks @utilitydive for the quote yesterday on...\n",
       "24987    @potus @morganstanley @cia can i get the grand...\n",
       "24988    why the fuck is @morganstanley even weighing i...\n",
       "24989                                                uscrn\n",
       "24990    does this correlate with the ucrn data that sh...\n",
       "24991    2020 #election #outlook: 4 scenarios for #inve...\n",
       "24992    obviously yes the climate has changed before. ...\n",
       "24993    deglobalization saves economy. globalization m...\n",
       "24994    @who - for every $1 invested in #mentalhealth ...\n",
       "24995    will deal-making continue to boom in 2020? mor...\n",
       "24996    try this: https://www.ldeo.columbia.edu/~dmcge...\n",
       "24997    anyone besides trump getting elected and peopl...\n",
       "24998    with highest number of immigrants from indian ...\n",
       "24999    put it this way, for the first time ever on mo...\n",
       "Name: Tweet_text, Length: 21388, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a data-frame for the tweet text column\n",
    "tweets = MS_final[[\"Tweet_text\"]]\n",
    "tweets.head()\n",
    "tweets['Tweet_text']\n",
    "\n",
    "#MS_final.head()['Tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        making paving material out of it is a really g...\n",
       "1        yep i don’t remember plastic as a child it was...\n",
       "2        lolokay why dont you look up the us debt befor...\n",
       "3        learn how morganstanley helps clients protect ...\n",
       "4        perfect friday field trip to  in mountain view...\n",
       "5                                                      NaN\n",
       "6        did you know that consolidating your assets co...\n",
       "7        americans had better quit arguing about who ge...\n",
       "8        up  down  up  down  i feel like a ping pong ba...\n",
       "9                                         glass recyclable\n",
       "10       “walk the ridge” and see that there are good p...\n",
       "11       extremely proud to work with advocates like ci...\n",
       "13       welcome new partners we are thrilled over a do...\n",
       "14       earlier this week we spent an amazing afternoo...\n",
       "15       hey  why is it taking months to get my decease...\n",
       "16       la divisione usa di deutsche bank non supera g...\n",
       "17       it will be so much worse  your orange benefact...\n",
       "18       yes this happens at big firms too  news fa bar...\n",
       "19       gli scheletri negli armadi vengono fuori deuts...\n",
       "22        sf volunteered with communitygrows for a thir...\n",
       "23       the hospital looked great glad we could help e...\n",
       "24                                           justiceforluz\n",
       "29       financials give up most or all of morning gain...\n",
       "30       the tenor of trade disputes is changing they n...\n",
       "31       china becoming more affluent and influential i...\n",
       "32       en alsonarlacampana con   y  mantendrán mismas...\n",
       "33       sat june th is the deadline to sign up for qua...\n",
       "34       this week the  podcast hosted aba economic adv...\n",
       "35       huge thank you to the team of amazing voluntee...\n",
       "36       in chinas lowertier cities the forecast is bul...\n",
       "                               ...                        \n",
       "24970                                         how can help\n",
       "24971    uncertainty health concerns unsecure tradingun...\n",
       "24972    all investors face a crisis when trusting morg...\n",
       "24973    will asset taking continue to boom in  by morg...\n",
       "24974    if you killed him then it was my order also i ...\n",
       "24975      the media is ruthless to politicians someone...\n",
       "24976    \"larger well capitalized european corporates a...\n",
       "24977    how about the corruption if wallstreet and    ...\n",
       "24978     youre being used as a political tool on the m...\n",
       "24979    alarmism is a word that’s absent from science ...\n",
       "24980    no i will just continue to point out inconsist...\n",
       "24981    i encourage you to write something about it an...\n",
       "24982    so the pristine temp stations that do not need...\n",
       "24983      i got this alert at  pm after my tweet what ...\n",
       "24984    halftime stats provided by  hoyas lead  at the...\n",
       "24985    the uscrn shows no increase in surface tempera...\n",
       "24986    thanks  for the quote yesterday on stranded in...\n",
       "24987       can i get the grand size dock a tot dropped...\n",
       "24988    why the fuck is  even weighing in on this get ...\n",
       "24989                                                uscrn\n",
       "24990    does this correlate with the ucrn data that sh...\n",
       "24991          election outlook  scenarios for investors  \n",
       "24992    obviously yes the climate has changed before w...\n",
       "24993    deglobalization saves economy globalization ma...\n",
       "24994      for every  invested in mentalhealth treatmen...\n",
       "24995    will dealmaking continue to boom in  morgan st...\n",
       "24996                                            try this \n",
       "24997    anyone besides trump getting elected and peopl...\n",
       "24998    with highest number of immigrants from indian ...\n",
       "24999    put it this way for the first time ever on mon...\n",
       "Name: Tweet_text, Length: 21388, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets = tweets.replace(\"https:(\\/\\/t\\.co\\/([A-Za-z0-9]|[A-Za-z]){10})\", '', regex = True)\n",
    "#tweets = tweets.replace(\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\", '', regex = True)\n",
    "\n",
    "\n",
    "##Removing urls\n",
    "tweets = tweets.replace('https?:\\/\\/.*[\\r\\n]*', '', regex = True)\n",
    "\n",
    "#text = re.sub(r\"https:(\\/\\/t\\.co\\/([A-Za-z0-9]|[A-Za-z]){10})\", \"\", text)\n",
    "\n",
    "#removing hashtags, numbers and twitter handles\n",
    "tweets = tweets.replace(\"[0-9]+\", '', regex = True)\n",
    "tweets = tweets.replace(\"#\", '', regex = True)\n",
    "tweets = tweets.replace(\"@[a-zA-Z0-9]+\", '', regex = True)\n",
    "\n",
    "#removing special characters\n",
    "tweets = tweets.replace(\"[,@!\\;'-?\\.$%_]\",'', regex = True)\n",
    "#tweets = tweets.replace('\"','', regex = True)\n",
    "\n",
    "tweets['Tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   making paving material really good use\n",
       "1        yep don’t remember plastic child glass paper t...\n",
       "2        lolokay dont look us debt obamatake seconds is...\n",
       "3        learn morganstanley helps clients protect asse...\n",
       "4        perfect friday field trip mountain view intern...\n",
       "5                                                      NaN\n",
       "6        did you know that consolidating your assets co...\n",
       "7        americans had better quit arguing about who ge...\n",
       "8        up  down  up  down  i feel like a ping pong ba...\n",
       "9                                         glass recyclable\n",
       "10       “walk the ridge” and see that there are good p...\n",
       "11       extremely proud to work with advocates like ci...\n",
       "13       welcome new partners we are thrilled over a do...\n",
       "14       earlier this week we spent an amazing afternoo...\n",
       "15       hey  why is it taking months to get my decease...\n",
       "16       la divisione usa di deutsche bank non supera g...\n",
       "17       it will be so much worse  your orange benefact...\n",
       "18       yes this happens at big firms too  news fa bar...\n",
       "19       gli scheletri negli armadi vengono fuori deuts...\n",
       "22        sf volunteered with communitygrows for a thir...\n",
       "23       the hospital looked great glad we could help e...\n",
       "24                                           justiceforluz\n",
       "29       financials give up most or all of morning gain...\n",
       "30       the tenor of trade disputes is changing they n...\n",
       "31       china becoming more affluent and influential i...\n",
       "32       en alsonarlacampana con   y  mantendrán mismas...\n",
       "33       sat june th is the deadline to sign up for qua...\n",
       "34       this week the  podcast hosted aba economic adv...\n",
       "35       huge thank you to the team of amazing voluntee...\n",
       "36       in chinas lowertier cities the forecast is bul...\n",
       "                               ...                        \n",
       "24970                                         how can help\n",
       "24971    uncertainty health concerns unsecure tradingun...\n",
       "24972    all investors face a crisis when trusting morg...\n",
       "24973    will asset taking continue to boom in  by morg...\n",
       "24974    if you killed him then it was my order also i ...\n",
       "24975      the media is ruthless to politicians someone...\n",
       "24976    \"larger well capitalized european corporates a...\n",
       "24977    how about the corruption if wallstreet and    ...\n",
       "24978     youre being used as a political tool on the m...\n",
       "24979    alarmism is a word that’s absent from science ...\n",
       "24980    no i will just continue to point out inconsist...\n",
       "24981    i encourage you to write something about it an...\n",
       "24982    so the pristine temp stations that do not need...\n",
       "24983      i got this alert at  pm after my tweet what ...\n",
       "24984    halftime stats provided by  hoyas lead  at the...\n",
       "24985    the uscrn shows no increase in surface tempera...\n",
       "24986    thanks  for the quote yesterday on stranded in...\n",
       "24987       can i get the grand size dock a tot dropped...\n",
       "24988    why the fuck is  even weighing in on this get ...\n",
       "24989                                                uscrn\n",
       "24990    does this correlate with the ucrn data that sh...\n",
       "24991          election outlook  scenarios for investors  \n",
       "24992    obviously yes the climate has changed before w...\n",
       "24993    deglobalization saves economy globalization ma...\n",
       "24994      for every  invested in mentalhealth treatmen...\n",
       "24995    will dealmaking continue to boom in  morgan st...\n",
       "24996                                            try this \n",
       "24997    anyone besides trump getting elected and peopl...\n",
       "24998    with highest number of immigrants from indian ...\n",
       "24999    put it this way for the first time ever on mon...\n",
       "Name: Tweet_text, Length: 21388, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "#stop_words = set(stopwords.words('english')) \n",
    "\n",
    "for i in range(5):\n",
    "    text = tweets[\"Tweet_text\"][i]\n",
    "    text_new = ' '.join([word for word in text.split() if word not in stopwords.words(\"english\")])\n",
    "    tweets['Tweet_text'][i] = text_new\n",
    "    \n",
    "tweets['Tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(tweets.shape[0]):\n",
    "#print(i)\n",
    "\n",
    "\n",
    "#word_tokens = word_tokenize(tweets[\"Tweet_text\"][0])\n",
    "\n",
    "\n",
    "#filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "#filtered_sentence = [] \n",
    "    \n",
    "#for w in word_tokens:\n",
    "    #if w not in stop_words:\n",
    "        #filtered_sentence.append(w) \n",
    "\n",
    "#tweets[\"Tweet_text\"][0].replace(tweets[\"Tweet_text\"][0], filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = tweets[\"Tweet_text\"][0]\n",
    "#text = ' '.join([word for word in text.split() if word not in stopwords.words(\"english\")])\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>making paving material really good use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yep don’t remember plastic child glass paper t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lolokay dont look us debt obamatake seconds is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn morganstanley helps clients protect asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect friday field trip mountain view intern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Tweet_text\n",
       "0             making paving material really good use\n",
       "1  yep don’t remember plastic child glass paper t...\n",
       "2  lolokay dont look us debt obamatake seconds is...\n",
       "3  learn morganstanley helps clients protect asse...\n",
       "4  perfect friday field trip mountain view intern..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_series = tweets['Tweet_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 'Tweets' dataframe has all the cleaned tweets. 'tweet_series' is a series version of the tweets. Below, 'tweet_json' contains cleaned tweets in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json = tweets.to_json(orient='values')\n",
    "#tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [making, paving, material, really, good, use]\n",
       "1    [yep, don’t, remember, plastic, child, glass, ...\n",
       "2    [lolokay, dont, look, us, debt, obamatake, sec...\n",
       "3    [learn, morganstanley, helps, clients, protect...\n",
       "4    [perfect, friday, field, trip, mountain, view,...\n",
       "Name: Tweet_text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizing all the tweets in series form\n",
    "tweet_vector = tweet_series.str.split()\n",
    "tweet_vector[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>User</th>\n",
       "      <th>Share</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>GeoSpatial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012846351309254656</td>\n",
       "      <td>https://twitter.com/CecilKeeler33/status/10128...</td>\n",
       "      <td>CecilKeeler33</td>\n",
       "      <td>MorganStanley</td>\n",
       "      <td>making paving material really good use</td>\n",
       "      <td>2018-06-29 23:52:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012846324956520448</td>\n",
       "      <td>https://twitter.com/Ddenham61/status/101284632...</td>\n",
       "      <td>Ddenham61</td>\n",
       "      <td>Derk1965</td>\n",
       "      <td>yep don’t remember plastic child glass paper t...</td>\n",
       "      <td>2018-06-29 23:52:36+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012837217251790848</td>\n",
       "      <td>https://twitter.com/tony_sabol/status/10128372...</td>\n",
       "      <td>tony_sabol</td>\n",
       "      <td>yeahokisee</td>\n",
       "      <td>lolokay dont look us debt obamatake seconds is...</td>\n",
       "      <td>2018-06-29 23:16:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012836868612808705</td>\n",
       "      <td>https://twitter.com/LindaKalatMS/status/101283...</td>\n",
       "      <td>LindaKalatMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>learn morganstanley helps clients protect asse...</td>\n",
       "      <td>2018-06-29 23:15:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#MorganStanley #cybersecurity #fraudprotection...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012835713065406464</td>\n",
       "      <td>https://twitter.com/newdoorventures/status/101...</td>\n",
       "      <td>newdoorventures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfect friday field trip mountain view intern...</td>\n",
       "      <td>2018-06-29 23:10:26+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>@MorganStanley</td>\n",
       "      <td>#CapitalCreatesChange</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_ID                                                URL  \\\n",
       "0  1012846351309254656  https://twitter.com/CecilKeeler33/status/10128...   \n",
       "1  1012846324956520448  https://twitter.com/Ddenham61/status/101284632...   \n",
       "2  1012837217251790848  https://twitter.com/tony_sabol/status/10128372...   \n",
       "3  1012836868612808705  https://twitter.com/LindaKalatMS/status/101283...   \n",
       "4  1012835713065406464  https://twitter.com/newdoorventures/status/101...   \n",
       "\n",
       "              User          Share  \\\n",
       "0    CecilKeeler33  MorganStanley   \n",
       "1        Ddenham61       Derk1965   \n",
       "2       tony_sabol     yeahokisee   \n",
       "3     LindaKalatMS            NaN   \n",
       "4  newdoorventures            NaN   \n",
       "\n",
       "                                          Tweet_text  \\\n",
       "0             making paving material really good use   \n",
       "1  yep don’t remember plastic child glass paper t...   \n",
       "2  lolokay dont look us debt obamatake seconds is...   \n",
       "3  learn morganstanley helps clients protect asse...   \n",
       "4  perfect friday field trip mountain view intern...   \n",
       "\n",
       "                        Date  Retweets  Favorites        Mentions  \\\n",
       "0  2018-06-29 23:52:42+00:00         0          0             NaN   \n",
       "1  2018-06-29 23:52:36+00:00         1          3             NaN   \n",
       "2  2018-06-29 23:16:24+00:00         0          0             NaN   \n",
       "3  2018-06-29 23:15:01+00:00         0          0             NaN   \n",
       "4  2018-06-29 23:10:26+00:00         2          4  @MorganStanley   \n",
       "\n",
       "                                            Hashtags  GeoSpatial  \n",
       "0                                                NaN         NaN  \n",
       "1                                                NaN         NaN  \n",
       "2                                                NaN         NaN  \n",
       "3  #MorganStanley #cybersecurity #fraudprotection...         NaN  \n",
       "4                              #CapitalCreatesChange         NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MS_final.head()\n",
    "MS_final.drop(columns = ['Tweet_text'])\n",
    "MS_final['Tweet_text'] = tweets\n",
    "\n",
    "MS_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet_text    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many empty tweets exist\n",
    "MS_final[['Tweet_text']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_final = MS_final.dropna(subset=['Tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>User</th>\n",
       "      <th>Share</th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>GeoSpatial</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012846351309254656</td>\n",
       "      <td>https://twitter.com/CecilKeeler33/status/10128...</td>\n",
       "      <td>CecilKeeler33</td>\n",
       "      <td>MorganStanley</td>\n",
       "      <td>making paving material really good use</td>\n",
       "      <td>2018-06-29 23:52:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[making, paving, material, really, good, use]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012846324956520448</td>\n",
       "      <td>https://twitter.com/Ddenham61/status/101284632...</td>\n",
       "      <td>Ddenham61</td>\n",
       "      <td>Derk1965</td>\n",
       "      <td>yep don’t remember plastic child glass paper t...</td>\n",
       "      <td>2018-06-29 23:52:36+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[yep, don, ’, t, remember, plastic, child, gla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012837217251790848</td>\n",
       "      <td>https://twitter.com/tony_sabol/status/10128372...</td>\n",
       "      <td>tony_sabol</td>\n",
       "      <td>yeahokisee</td>\n",
       "      <td>lolokay dont look us debt obamatake seconds is...</td>\n",
       "      <td>2018-06-29 23:16:24+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lolokay, dont, look, us, debt, obamatake, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012836868612808705</td>\n",
       "      <td>https://twitter.com/LindaKalatMS/status/101283...</td>\n",
       "      <td>LindaKalatMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>learn morganstanley helps clients protect asse...</td>\n",
       "      <td>2018-06-29 23:15:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#MorganStanley #cybersecurity #fraudprotection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[learn, morganstanley, helps, clients, protect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012835713065406464</td>\n",
       "      <td>https://twitter.com/newdoorventures/status/101...</td>\n",
       "      <td>newdoorventures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfect friday field trip mountain view intern...</td>\n",
       "      <td>2018-06-29 23:10:26+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>@MorganStanley</td>\n",
       "      <td>#CapitalCreatesChange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[perfect, friday, field, trip, mountain, view,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_ID                                                URL  \\\n",
       "0  1012846351309254656  https://twitter.com/CecilKeeler33/status/10128...   \n",
       "1  1012846324956520448  https://twitter.com/Ddenham61/status/101284632...   \n",
       "2  1012837217251790848  https://twitter.com/tony_sabol/status/10128372...   \n",
       "3  1012836868612808705  https://twitter.com/LindaKalatMS/status/101283...   \n",
       "4  1012835713065406464  https://twitter.com/newdoorventures/status/101...   \n",
       "\n",
       "              User          Share  \\\n",
       "0    CecilKeeler33  MorganStanley   \n",
       "1        Ddenham61       Derk1965   \n",
       "2       tony_sabol     yeahokisee   \n",
       "3     LindaKalatMS            NaN   \n",
       "4  newdoorventures            NaN   \n",
       "\n",
       "                                          Tweet_text  \\\n",
       "0             making paving material really good use   \n",
       "1  yep don’t remember plastic child glass paper t...   \n",
       "2  lolokay dont look us debt obamatake seconds is...   \n",
       "3  learn morganstanley helps clients protect asse...   \n",
       "4  perfect friday field trip mountain view intern...   \n",
       "\n",
       "                        Date  Retweets  Favorites        Mentions  \\\n",
       "0  2018-06-29 23:52:42+00:00         0          0             NaN   \n",
       "1  2018-06-29 23:52:36+00:00         1          3             NaN   \n",
       "2  2018-06-29 23:16:24+00:00         0          0             NaN   \n",
       "3  2018-06-29 23:15:01+00:00         0          0             NaN   \n",
       "4  2018-06-29 23:10:26+00:00         2          4  @MorganStanley   \n",
       "\n",
       "                                            Hashtags  GeoSpatial  \\\n",
       "0                                                NaN         NaN   \n",
       "1                                                NaN         NaN   \n",
       "2                                                NaN         NaN   \n",
       "3  #MorganStanley #cybersecurity #fraudprotection...         NaN   \n",
       "4                              #CapitalCreatesChange         NaN   \n",
       "\n",
       "                                           tokenized  \n",
       "0      [making, paving, material, really, good, use]  \n",
       "1  [yep, don, ’, t, remember, plastic, child, gla...  \n",
       "2  [lolokay, dont, look, us, debt, obamatake, sec...  \n",
       "3  [learn, morganstanley, helps, clients, protect...  \n",
       "4  [perfect, friday, field, trip, mountain, view,...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MS_final['tokenized_text'] = MS_final['Tweet_text'].apply(word_tokenize)\n",
    "#tokenizing the tweets\n",
    "MS_final['tokenized'] = MS_final.apply(lambda x: tt.tokenize(x['Tweet_text']), axis=1)\n",
    "\n",
    "MS_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/44173624/how-to-apply-nltk-word-tokenize-library-on-a-pandas-dataframe-for-twitter-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/biaslyai/beginners-guide-to-text-preprocessing-in-python-2cbeafbf5f44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>making paving material really good use</td>\n",
       "      <td>[making, paving, material, really, good, use]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yep don’t remember plastic child glass paper t...</td>\n",
       "      <td>[yep, don, ’, t, remember, plastic, child, gla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lolokay dont look us debt obamatake seconds is...</td>\n",
       "      <td>[lolokay, dont, look, us, debt, obamatake, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn morganstanley helps clients protect asse...</td>\n",
       "      <td>[learn, morganstanley, helps, clients, protect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perfect friday field trip mountain view intern...</td>\n",
       "      <td>[perfect, friday, field, trip, mountain, view,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Tweet_text  \\\n",
       "0             making paving material really good use   \n",
       "1  yep don’t remember plastic child glass paper t...   \n",
       "2  lolokay dont look us debt obamatake seconds is...   \n",
       "3  learn morganstanley helps clients protect asse...   \n",
       "4  perfect friday field trip mountain view intern...   \n",
       "\n",
       "                                           tokenized  \n",
       "0      [making, paving, material, really, good, use]  \n",
       "1  [yep, don, ’, t, remember, plastic, child, gla...  \n",
       "2  [lolokay, dont, look, us, debt, obamatake, sec...  \n",
       "3  [learn, morganstanley, helps, clients, protect...  \n",
       "4  [perfect, friday, field, trip, mountain, view,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.dropna(subset=['Tweet_text'])\n",
    "tweets['tokenized'] = tweets.apply(lambda x: tt.tokenize(x['Tweet_text']), axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data-frame MS_final has been updated with the tokenized tweets. 'tweets' just contains the tweets. This dataframe can be used for clean execution of other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
